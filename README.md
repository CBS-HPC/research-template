# ğŸ§ª Reproducible Research Template: Structured Workflows and Replication Packages

![Repo size](https://img.shields.io/github/repo-size/CBS-HPC/research-template)
![Last commit](https://img.shields.io/github/last-commit/CBS-HPC/research-template)
[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![License: CC BY 4.0](https://img.shields.io/badge/license-CC--BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)
![Open issues](https://img.shields.io/github/issues/CBS-HPC/research-template)
![Pull requests](https://img.shields.io/github/issues-pr/CBS-HPC/research-template)
![Windows](https://img.shields.io/badge/tested%20on-Windows-blue?logo=windows&logoColor=white)
![Linux](https://img.shields.io/badge/tested%20on-Bash%20(Ubuntu)-blue?logo=linux&logoColor=white)


> âš ï¸ **This repository is under active development. Features, structure, and documentation may change.**

This project template is designed to help **CBS researchers** create structured, automated, and publication-ready workflows aligned with the principles of **Open Science** and **FAIR** data practices (Findable, Accessible, Interoperable, and Reusable).

Built with [Cookiecutter](https://cookiecutter.readthedocs.io/en/latest/), the template supports **Python**, **R**, **Stata** and **Matlab**, and provides an integrated framework for organizing code, managing datasets, tracking dependencies, enabling version control, and backing up research securely.

Whether you're preparing a replication package for publication, submitting data and code for peer review, or organizing internal research, this tool helps you streamline reproducible research workflows tailored to the needs of the **CBS research community**.

> âœ… This template has been tested on **Windows (PowerShell)** and **Ubuntu (bash)** environments.

---

ğŸ” **Key features:**

- ğŸ“ Effective project structure for transparent and consistent workflows  
- ğŸ§¬ Multi-language support: Python, R, Stata and Matlab 
- ğŸ—ƒï¸ Version control via Git, Datalad, or DVC  
- ğŸ“¦ Automated script scaffolding for analysis, modeling, and visualization  
- ğŸ” Environment management via Conda or venv  
- â˜ï¸ Backup integration with DeiC Storage, Dropbox, and OneDrive  
- ğŸš€ Remote repository setup with GitHub, GitLab, or Codeberg  
- ğŸ§¾ Auto-generated metadata files: `README.md`, `LICENSE.txt`, `CITATION.cff`  
- ğŸ§° Installation guides and activation scripts for both Windows and Bash  
- ğŸ“‘ Structured documentation of all files, code, and datasets
- ğŸ“„ Support for DCAS-aligned replication packages  

This template is developed and maintained by the **CBS High-Performance Computing (HPC)** team to promote reproducibility, collaboration, and compliance in computational research at Copenhagen Business School.

---

## ğŸ› ï¸ Requirements

- [**Python 3.9+**](https://www.python.org/downloads/) â€“ Required to run the template and environment setup scripts  
- [**cookiecutter**](https://cookiecutter.readthedocs.io/en/latest/) â€“ Used to generate the project structure  
- [**Git**](https://git-scm.com/downloads) *(optional)* â€“ Git is optional for project generation but **required** if using version control or pushing to remote repositories.

Install Cookiecutter:

```bash
pip install cookiecutter
```

> If Git or other tools are missing, the template will offer to download and configure them for you.

---

## ğŸ—ï¸ Generate a New Project

This template can be used either online (via GitHub) or offline (manually downloaded).

<details>
<summary>ğŸ“¦ Online (with Git)</summary>

Use this option if Git is installed and you want to fetch the template directly from GitHub:

```bash
cookiecutter gh:CBS-HPC/research-template
```

</details>

<details>
<summary>ğŸ“ Offline (Local Installation)</summary>

If Git is **not installed**, you can still use the template by downloading it manually:

1. Go to [https://github.com/CBS-HPC/research-template](https://github.com/CBS-HPC/research-template)  
2. Click the green **â€œCodeâ€** button, then choose **â€œDownload ZIPâ€**  
3. Extract the ZIP file to a folder of your choice  
4. Run Cookiecutter locally:

```bash
cookiecutter path/to/research-template
```

> âš ï¸ Do **not** use `git clone` if Git is not installed. Manual download is required in this case.

</details>

---

## ğŸ§¾ Setup Options

This template guides you through a series of interactive prompts to configure your projectâ€”including version control, environment setup, backup destinations, and remote repository platforms. Click below to expand each section for a visual breakdown of all setup steps.

<details>
<summary>ğŸ“¦ Project Metadata</summary>

Provide core metadata for your projectâ€”used for naming, documentation, citation, and licensing.

```
â”œâ”€â”€ project_name              â†’ Human-readable name
â”œâ”€â”€ repo_name                 â†’ Folder and repository name
â”œâ”€â”€ description               â†’ Short summary of the project
â”œâ”€â”€ author_name               â†’ Your full name
â”œâ”€â”€ email                     â†’ Your CBS email
â”œâ”€â”€ orcid                     â†’ Your ORCID researcher ID
â”œâ”€â”€ version                   â†’ Initial version number (e.g., 0.0.1)
â”œâ”€â”€ code_license              â†’ [MIT | BSD-3-Clause | Apache-2.0 | None]
â”œâ”€â”€ documentation_license     â†’ [CC-BY-4.0 | CC0-1.0 | None]
â”œâ”€â”€ data_license              â†’ [CC-BY-4.0 | CC0-1.0 | None]
```

This information is used to auto-generate:

- `README.md` â€“ populated with title, description, and author info  
- `LICENSE.txt` â€“ includes license sections for code, documentation, and data  
- `CITATION.cff` â€“ for machine-readable academic citation


### ğŸ”‘ License Descriptions

**Code Licenses:**

- [**MIT**](https://opensource.org/licenses/MIT) â€“ Very permissive, short license. Allows reuse with attribution.  
- [**BSD-3-Clause**](https://opensource.org/license/bsd-3-clause/) â€“ Permissive, but includes a non-endorsement clause.  
- [**Apache-2.0**](https://www.apache.org/licenses/LICENSE-2.0) â€“ Like MIT, but includes explicit patent protection.  

**Documentation Licenses:**

- [**CC-BY-4.0**](https://creativecommons.org/licenses/by/4.0/) â€“ Requires attribution, allows commercial and derivative use.  
- [**CC0-1.0**](https://creativecommons.org/publicdomain/zero/1.0/) â€“ Places documentation in the public domain (no attribution required).

**Data Licenses:**

- [**CC-BY-4.0**](https://creativecommons.org/licenses/by/4.0/) â€“ Allows reuse and redistribution with attribution.  
- [**CC0-1.0**](https://creativecommons.org/publicdomain/zero/1.0/) â€“ Public domain dedication for unrestricted reuse.

> â„¹ï¸ If â€œNoneâ€ is selected, the corresponding section will be omitted from the LICENSE file.

</details>

<details>
<summary>ğŸ§¬ Programming Language & Script Templates</summary>

Choose your primary scripting language. The template supports multi-language projects and automatically generates a modular codebase tailored to your selection.

```
â”œâ”€â”€ programming_language      â†’ [Python | R | Stata | Matlab | None]
â”‚   â””â”€â”€ If R/Stata/Matlab selected:
â”‚       â””â”€â”€ Prompt for executable path if not auto-detected
```

If you select **R**, **Stata** or **Matlab** the template will prompt for the path to the installed software if it is not auto-detected.

### ğŸ› ï¸ Script Generation

Script generation is **language-agnostic**: based on your selected language, the template will create files with the appropriate extensions:

- `.py` (scripts) and `.ipynb` (notebooks) for Python
- `.R` (scripts) and `.Rmd` (notebooks) for R
- `.m`(scripts) and `.mlx` (notebooks) for Matlab 
- `.do` (scripts) and `.ipynb` (notebooks) for Stata


These starter scripts are placed in the `src/` directory and include:

```
â”œâ”€â”€ s00_main.*                  â†’ orchestrates the full pipeline
â”œâ”€â”€ s00_workflow.*              â†’ notebook (.ipynb, .Rmd, .mlx) orchestrating the full pipeline
â”œâ”€â”€ s01_install_dependencies.*  â†’ installs any missing packages required for the project
â”œâ”€â”€ s02_utils.*                 â†’ shared helper functions (not directly executable)
â”œâ”€â”€ s03_data_collection.*       â†’ imports or generates raw data
â”œâ”€â”€ s04_preprocessing.*         â†’ cleans and transforms data
â”œâ”€â”€ s05_modeling.*              â†’ fits models and generates outputs
â”œâ”€â”€ s06_visualization.*         â†’ creates plots and summaries
â”œâ”€â”€ get_dependencies.*          â†’ retrieves and checks required dependencies for the project environment. (Utilised)

```

Each script is structured to:

- Define a `main()` function or logical entry point (where applicable)  
- Automatically resolve project folder paths (`data/00_raw/`, `results/figures/`, etc.)  
- Remain passive unless directly called or imported  
- Support reproducible workflows by default

> ğŸ§© Scripts are designed to be flexible and modular: you can run them individually, chain them in `main.*`, or explore them interactively using Jupyter or RMarkdown.

</details>

<details>
<summary>ğŸ§ª Environment Configuration</summary>

Set up isolated virtual environments using **Conda**, **venv**, or your systemâ€™s **base installation**.

```
â”œâ”€â”€ R environment (if R used)
â”‚   â””â”€â”€ env_manager_r         â†’ [Conda | Base Installation]
â”‚       â”œâ”€â”€ If Conda:         â†’ Prompt for R version
â”‚       â””â”€â”€ If Base:          â†’ Uses system-installed R
â”œâ”€â”€ Python environment
â”‚   â””â”€â”€ env_manager_python    â†’ [Conda | Venv | Base Installation]
â”‚       â”œâ”€â”€ If Conda:         â†’ Prompt for Python version
â”‚       â”œâ”€â”€ If Venv:          â†’ Uses current Python kernel version
â”‚       â””â”€â”€ If Base:          â†’ Uses system-installed Python
â”œâ”€â”€ Proprietary software (if selected)
â”‚   â””â”€â”€ [Stata | Matlab | R]
â”‚       â”œâ”€â”€ Searches system PATH for installed application
â”‚       â””â”€â”€ Prompts user for executable path if not found
```

**Environment manager options:**

- [**Conda**](https://docs.conda.io/en/latest/) â€“ A popular environment and package manager that supports both Python and R. Enables exact version control and cross-platform reproducibility.  
- [**venv**](https://docs.python.org/3/library/venv.html) â€“ Pythonâ€™s built-in tool for creating lightweight, isolated environments. Ideal for Python-only projects.  
- **Base Installation** â€“ No virtual environment is created. Dependencies are installed directly into your system-wide Python or R installation.

Regardless of your choice, the following files are generated to document your environment:

- `environment.yml` â€“ Conda-compatible list of dependencies  
- `requirements.txt` â€“ pip-compatible Python package list  
- `renv.lock` â€“ (if R is selected) snapshot of R packages using the `renv` package  

> âš ï¸ When using **venv** or **base installation**, the `environment.yml` file is created **without Conda's native environment tracking**. As a result, it may be **less accurate or reproducible** than environments created with Conda.  
> âš ï¸ If proprietary software (e.g., Stata, Matlab, R) is selected, the system will first **search your PATH**. If not found, youâ€™ll be prompted to manually enter the executable path.  
> ğŸ’¡ Conda will be downloaded and installed automatically if it's not already available.

</details>


<details>
<summary>ğŸ—ƒï¸ Version Control</summary>

Choose a system to version your code (and optionally your data).

```
â”œâ”€â”€ version_control           â†’ [Git | Datalad | DVC | None]
â”‚   â”œâ”€â”€ Git:
â”‚   â”‚   â”œâ”€â”€ Prompt for Git user.name and user.email
â”‚   â”‚   â”œâ”€â”€ Initializes Git repo in project root
â”‚   â”‚   â””â”€â”€ Initializes separate Git repo in `data/`
â”‚   â”œâ”€â”€ Datalad:
â”‚   â”‚   â”œâ”€â”€ Initializes Git repo (if not already)
â”‚   â”‚   â””â”€â”€ Initializes a Datalad dataset in `data/` (nested Git repo)
â”‚   â””â”€â”€ DVC:
â”‚       â”œâ”€â”€ Initializes Git repo (if not already)
â”‚       â”œâ”€â”€ Runs `dvc init` to create a DVC project
â”‚       â””â”€â”€ Configures `data/` as a DVC-tracked directory
```

This template supports several version control systems to suit different workflows:

- [**Git**](https://git-scm.com/) â€“ general-purpose version control for code and text files  
- [**Datalad**](https://www.datalad.org/) â€“ for data-heavy, file-based versioning; designed to support **FAIR** principles and **Open Science** workflows  
- [**DVC**](https://dvc.org/) â€“ for machine learning pipelines, dataset tracking, and model versioning

### ğŸ”§ How it works:

- **Git**: initializes the project root as a Git repository  
  - Also creates a separate Git repo in `data/` to track datasets independently  
- **Datalad**: builds on Git by creating a [Datalad dataset](https://handbook.datalad.org/en/latest/basics/101-137-datasets.html) in `data/`  
- **DVC**: runs `dvc init` and sets up `data/` as a [DVC-tracked directory](https://dvc.org/doc/start/data-management) using external storage and `.dvc` files

### ğŸ“ Auto-generated `.gitignore` includes:

```
â”œâ”€â”€ data/                  â†’ 00_raw, 01_interim and 02_processed data folders
â”œâ”€â”€ bin/                   â†’ local binaries (e.g., rclone)
â”œâ”€â”€ env/, __pycache__/     â†’ Python virtual environments and caches
â”œâ”€â”€ .vscode/, .idea/       â†’ IDE and editor configs
â”œâ”€â”€ .DS_Store, *.swp       â†’ OS/system-generated files
â”œâ”€â”€ .ipynb_checkpoints/    â†’ Jupyter notebook checkpoints
â”œâ”€â”€ .coverage, *.log       â†’ logs, test coverage reports
```

> ğŸ§¹ These defaults help keep your repository clean, portable, and reproducible.

> âš™ï¸ If **Git**, **Datalad**, or **DVC** (or their dependencies) are not detected, the template will automatically download and install them during setup.
> This ensures you can use advanced version control tools without manual pre-installation.
</details>

<details>
<summary>â˜ï¸ Backup with Rclone</summary>

This template supports automated backup to **CBS-approved storage solutions** using [`rclone`](https://rclone.org).

```
â”œâ”€â”€ remote_backup             â†’ [DeIC | Dropbox | OneDrive | Local | Multiple | None]
â”‚   â”œâ”€â”€ DeIC:
â”‚   â”‚   â”œâ”€â”€ Prompt for CBS email
â”‚   â”‚   â””â”€â”€ Prompt for password (encrypted)
â”‚   â”œâ”€â”€ Dropbox / OneDrive:
â”‚   â”‚   â”œâ”€â”€ Prompt for email
â”‚   â”‚   â””â”€â”€ Prompt for password (encrypted)
â”‚   â”œâ”€â”€ Local:
â”‚   â”‚   â””â”€â”€ Prompt to choose a local destination path
â”‚   â””â”€â”€ Multiple:
â”‚       â””â”€â”€ Allows choosing several of the above
```

Supported backup targets include:

- [**DeIC Storage**](https://storage.deic.dk/) â€“ configured via **SFTP with password and MFA** (see instructions under â€œSetup â†’ SFTPâ€)  
- [**Dropbox**](https://www.dropbox.com/)  
- [**OneDrive**](https://onedrive.live.com/)  
- **Local** storage â€“ backup to a folder on your own system  
- **Multiple** â€“ select any combination of the above

> ğŸ” All credentials are stored in `rclone.conf`.  
> â˜ï¸ `rclone` is automatically downloaded and installed if not already available on your system.

</details>

<details>
<summary>ğŸ“¡ Remote Repository Setup</summary>

Automatically create and push to a Git repository on a remote hosting platform.

```
â”œâ”€â”€ remote_repo               â†’ [GitHub | GitLab | Codeberg | None]
â”‚   â””â”€â”€ If selected:
â”‚       â”œâ”€â”€ Prompt for username
â”‚       â”œâ”€â”€ Choose visibility: [private | public]
â”‚       â””â”€â”€ Provide personal access token (stored in `.env`)
```

Supported platforms include:

- [**GitHub**](https://github.com) â€“ the most widely used platform for open source and academic collaboration. Supports seamless repo creation, authentication, and automation.
- [**GitLab**](https://gitlab.com) â€“ a DevOps platform that supports both self-hosted and cloud-hosted repositories. Ideal for collaborative development with built-in CI/CD pipelines.
- [**Codeberg**](https://codeberg.org) â€“ a privacy-focused Git hosting service powered by [Gitea](https://about.gitea.com). Community-driven and compliant with European data governance standards.

Repositories are created using the **HTTPS API**, and authenticated with **personal access tokens**.

> ğŸ›¡ï¸ Your credentials and tokens are securely stored in the `.env` file and never exposed in plain text.

</details>

---
## ğŸ§¾ Project Structure and Usage

This template generates a standardized, reproducible project layout. It separates raw data, code, documentation, setup scripts, and outputs to support collaboration, transparency, and automation.

<details>
<summary>ğŸ“ Directory Structure</summary>

You can find or update human-readable file descriptions in `file_descriptions.json`.

```
â”œâ”€â”€ .cookiecutter             # Cookiecutter configuration used to generate this project
â”œâ”€â”€ .git                      # Git repository metadata
â”œâ”€â”€ .gitignore                # Files/directories excluded from Git version control
â”œâ”€â”€ .rcloneignore             # Files/directories excluded from Rclone backup
â”œâ”€â”€ .treeignore               # Files excluded from file tree utilities or visualizations
â”œâ”€â”€ CITATION.cff              # Machine-readable citation metadata for scholarly reference
â”œâ”€â”€ DCAS template/            # Template for DCAS-compliant replication packages
â”‚   â””â”€â”€ README.md             # README for the DCAS template
â”œâ”€â”€ LICENSE.txt               # Project license file
â”œâ”€â”€ README.md                 # Main README with usage and documentation
â”œâ”€â”€ activate.*                # Script to activate the environment (either `.ps1` or `.sh`)
â”œâ”€â”€ deactivate.*              # Script to deactivate the environment (either `.ps1` or `.sh`)
â”œâ”€â”€ bin/                      # Local tools (e.g., rclone binaries, installers)
â”œâ”€â”€ data/                     # Structured project data directory
â”‚   â”œâ”€â”€ .git/                 # Standalone Git repo for tracking datasets
â”‚   â”œâ”€â”€ .gitlog               # Git log for the data repository
â”‚   â”œâ”€â”€ 00_raw/                  # Original, immutable input data
â”‚   â”œâ”€â”€ 01_interim/              # Intermediate data created during processing
â”‚   â””â”€â”€ 02_processed/            # Final, clean data ready for analysis
â”œâ”€â”€ docs/                     # Project documentation, reports, or rendered outputs
â”œâ”€â”€ environment.yml           # Conda-compatible environment definition (Python/R)
â”œâ”€â”€ file_descriptions.json    # JSON file with editable descriptions for all project files
â”œâ”€â”€ requirements.txt          # pip-compatible list of Python dependencies
â”œâ”€â”€ results/                  # Results generated by the project
â”‚   â””â”€â”€ figures/              # Charts, plots, and other visual outputs
â”œâ”€â”€ setup/                    # Internal setup module for environment config and CLI tools
â”‚   â”œâ”€â”€ dependencies.txt      # List of Python dependencies for `setup` module  
â”‚   â”œâ”€â”€ setup.py              # Setup script to register the project as a Python package
â”‚   â””â”€â”€ utils/                # Utility functions and scripts for environment setup
â””â”€â”€ src (R/stata)/                  # Source code for data processing, analysis, and reporting
    â”œâ”€â”€ dependencies.txt            # List of dependencies for `src` module  
    â”œâ”€â”€ get_dependencies.*          # retrieves and checks required packages required for the project (Utilised)
    â”œâ”€â”€ s00_main.*                  # Orchestrates the full workflow pipeline
    â”œâ”€â”€ s00_workflow.*              # Interactive workflow (e.g., Jupyter notebook or RMarkdown)
    â”œâ”€â”€ s01_install_dependencies.*  # Installs any missing packages required for the project
    â”œâ”€â”€ s02_utils.*                 # Shared helper functions for reuse across script
    â”œâ”€â”€ s03_data_collection.*       # Imports or generates raw data from external sources
    â”œâ”€â”€ get_dependencies.*          # retrieves and checks required packages required for the project (Utilised)
    â”œâ”€â”€ s04_preprocessing.*         # Cleans and transforms raw input data
    â”œâ”€â”€ s05_modeling.*              # Performs modeling, estimation, or machine learning
    â”œâ”€â”€ s06_visualization.*         # Creates plots, charts, and visual summaries
```


> ğŸ” `activate.*` and `deactivate.*` are either PowerShell (`.ps1`) or Bash (`.sh`) scripts, depending on your platform (Windows or macOS/Linux).

> âœ³ï¸ Script file extensions (`.py`, `.R`, `.do`, `.m`) are determined by the programming language selected during project setup.

</details>

<details>
<summary>ğŸš€ Project Activation</summary>

To configure the project's environmentâ€”including project paths, environment variables, and virtual environmentsâ€”run the activation script for your operating system. These scripts read settings from the `.env` file.

### ğŸªŸ Windows (PowerShell)

**Activate:**

```powershell
./activate.ps1
```

**Deactivate:**

```powershell
./deactivate.ps1
```

### ğŸ§ macOS / Linux (bash)

**Activate:**

```bash
source activate.sh
```

**Deactivate:**

```bash
source deactivate.sh
```

</details>

<details>
<summary>ğŸ“… Unit Testing and Continuous Integration (CI)</summary>

This template includes built-in support for **unit testing** and **CI automation** across Python, R, MATLAB, and Stata to promote research reliability and reproducibility.

---

### ğŸ§ª Unit Testing

Unit test files are automatically generated for core analysis scripts and placed in a unified `tests/` folder during setup. The structure varies slightly by language:

| Language | Test Framework     | Code Folder | Test Folder       | Test File Format |
| -------- | ------------------ | ----------- | ----------------- | ---------------- |
| Python   | `pytest`           | `src/`      | `tests/`          | `test_*.py`      |
| R        | `testthat`         | `R/`        | `tests/testthat/` | `test-*.R`       |
| MATLAB   | `matlab.unittest`  | `src/`      | `tests/`          | `test_*.m`       |
| Stata    | `.do` script-based | `stata/do/` | `tests/`          | `test_*.do`      |

Tests are automatically scaffolded to match your workflow scripts (e.g., `s00_main`, `s04_preprocessing`). They can be run locally, in CI, or as part of a pipeline.

---

### ğŸ“„ Example Layouts and Test Commands

**Python**

Project structure:
```
src/s00_main.py
tests/test_s00_main.py
```

Run tests:
```
pytest
```

**R**
Project structure:
```
R/s00_main.R
tests/testthat/test-s00_main.R
```

Run tests:
```
testthat::test_dir("tests/testthat")
```
From command line:
```
Rscript -e 'testthat::test_dir("tests/testthat")'
```

**Matlab**
Project structure:
```
src/s00_main.m
tests/test_s00_main.m
```

Run tests in MATLAB:
```
results = runtests('tests');
assert(all([results.Passed]), 'Some tests failed')
```
From command line:
```
matlab -batch "results = runtests('tests'); assert(all([results.Passed]), 'Some tests failed')"
```

**Stata**
Project structure:
```
stata/do/s00_main.do
tests/test_s00_main.do
```

Run tests in Stata:
```
do tests/test_s00_main.do
```
Or in batch mode:
```
stata -b do tests/test_s00_main.do
```

### ğŸ§ª Test Development Guidelines

Writing good tests ensures that your code behaves as expected and simplifies debugging and maintenance.

Here are best practices for test development:

- âœ… Focus on **core logic and data transformations** â€” test data cleaning, modeling, and utility functions.
- âœ… Include **edge cases** â€” e.g., missing values, invalid inputs, or empty datasets.
- âœ… Keep tests **independent and repeatable** â€” donâ€™t rely on external state or prior test outcomes.
- âœ… Use **assertions appropriate for your language**:
  - `assert` in Python
  - `expect_equal()`, `expect_error()` in R/testthat
  - `verifyEqual()`, `verifyTrue()` in MATLAB
  - `assert` in Stata
- âœ… Organize tests to mirror your codebase (e.g., `s05_modeling.py` â†’ `test_s05_modeling.py`)

> ğŸ§ª Tests donâ€™t need to be exhaustive â€” aim for **critical correctness** and **reproducibility**.

---

### ğŸ”§ Test-Driven Development (TDD)

Test-Driven Development (TDD) is a workflow that emphasizes writing tests **before** writing the actual implementation. It's especially useful for ensuring reproducibility and correctness in research workflows.

**TDD workflow:**
1. **Write a failing test** that describes the desired behavior
2. **Implement the minimum code** needed to make the test pass
3. **Refactor** the implementation (if needed) while keeping the test green

**Benefits in research projects:**
- Ensures reproducible and validated results
- Encourages modular, testable code
- Prevents regressions when modifying scripts

> ğŸ’¡ TDD fits naturally with script scaffolding in this template. Each script has a corresponding test file scaffold to encourage this workflow.

---

### âš™ï¸ Continuous Integration (CI)

The template supports CI pipelines on all major platforms:

- **GitHub Actions**
- **GitLab CI/CD**
- **Codeberg CI** (via Woodpecker)

CI configurations are auto-generated based on your language and repository host, and placed in the appropriate file:

| Platform | Config File                |
| -------- | -------------------------- |
| GitHub   | `.github/workflows/ci.yml` |
| GitLab   | `.gitlab-ci.yml`           |
| Codeberg | `.woodpecker.yml`          |

Each pipeline performs the following:

1. Installs the appropriate language environment
2. Installs dependencies (e.g., `requirements.txt`, `renv.lock`)
3. Runs tests in the `tests/` directory
4. Outputs test logs and error reports

For R projects, CI will run `renv::restore(project = 'R')` if `R/renv.lock` exists. Otherwise, it falls back to `install.packages()`.

---

### ğŸ”„ CI Config via CLI

CI can be configured to the selected platform using the built-in CLI command:

```
ci_config 
```

This works by renaming .yml files to .yml.disabled and back. It's useful for disabling CI during development
  
  ğŸšª CI is disabled by default after project generation. Use ci-config --enable when you're ready to activate it.


### ğŸ”„ CI Control via CLI

CI can be toggled on or off using the built-in CLI command:

```
ci_control --enable 
ci_control --disable 
```

</details>


<details>
<summary>ğŸ”§ CLI Tools</summary>

The `setup` Python package provides a collection of command-line utilities to support project configuration, dependency management, documentation, and reproducibility workflows.

> â„¹ï¸ **Note**: The `setup` package is **automatically installed** during project setup.  
> You can also manually install or reinstall it using:  
> `pip install -e ./setup`

Once installed, the following CLI commands become available from the terminal:

| Command                     | Description                                                                                       |
|-----------------------------|---------------------------------------------------------------------------------------------------|
| `push-backup`                | Executes a full project backup using preconfigured rules and paths.                               |
| `set-dataset`               | Initializes or registers datasets (e.g., add metadata, sync folders).                            |
| `update-dependencies`       | Retrieves and updates Python and R dependencies listed in `setup/` and `src/`.                   |
| `run-setup` *(in progress)* | Main entry point to initialize or reconfigure the project environment.                           |
| `update-readme`             | Regenerates the `README.md` with updated metadata and file structure.                            |
| `reset-templates`           | Resets or regenerates script templates in `src/` based on project language.                      |
| `code-examples`             | Generates language-specific example code and notebooks (Python, R, etc.).                   |
| `dcas-migrate` *(in progress)* | Validates and migrates the project structure to DCAS (Data and Code Availability Standard) format. |

### ğŸ› ï¸ Usage

After activating your environment, run commands like:

```bash
run-setup
set-dataset
update-requirements
```

</details>

<details>
<summary>ğŸ—‚ï¸ Configuration Files (Root-Level)</summary>

The following configuration files are placed in the root directory and used by tools for managing environments, templates, backups, and project metadata.

| File                      | Purpose                                                                                             |
|---------------------------|-----------------------------------------------------------------------------------------------------|
| `.gitignore`              | Excludes unnecessary files from Git version control                                                 |
| `.rcloneignore`           | Excludes files and folders from Rclone-based backups                                                |
| `.treeignore`             | Filters out directories from project tree visualizations                                            |
| `.cookiecutter`           | Cookiecutter metadata for project initialization                                                    |
| `.env`                    | Defines environment-specific variables (e.g., paths, tokens, settings); typically excluded from Git |
| `environment.yml`         | Conda environment definition for installing Python and R dependencies                               |
| `requirements.txt`        | pip-compatible Python dependencies                                                                  |
| `renv.lock`               | Captures exact versions of R packages used (if R is selected)                                       |
| `file_descriptions.json`  | JSON file containing editable metadata for the directory structure; used by setup and documentation tools |

</details>

---

## ğŸ“š DCAS Compatibility

This template is designed to support the creation of replication packages that are fully compatible with the [Data and Code Availability Standard (DCAS)](https://datacodestandard.org/), a widely endorsed initiative to promote transparency and reproducibility in social science research.

By structuring code, data, metadata, and documentation into clear, well-separated foldersâ€”with standard naming conventions, licensing, and README scaffoldsâ€”the template helps you align with the expectations of journals that require or recommend DCAS compliance.

Key features that support DCAS alignment:

- ğŸ“‚ Separation of raw, interim, and processed data
- ğŸ“œ Auto-generated licensing and citation metadata (`LICENSE.txt`, `CITATION.cff`)
- ğŸ“‘ Structured file annotations via `file_descriptions.json`
- ğŸ§ª Scripted environment setup and reproducibility utilities
- ğŸ“„ Optional DCAS template folder with journal-ready content

This format is consistent with the [AEA Data Editorâ€™s guidance](https://aeadataeditor.github.io/aea-de-guidance/preparing-for-data-deposit.html) and the broader Social Science Data Editors' best practices.

**Examples of journals endorsing the DCAS standard:**

- [American Economic Journal: Applied Economics](https://www.aeaweb.org/journals/applied-economics)
- [Econometrica](https://www.econometricsociety.org/publications/econometrica)
- [Economic Inquiry](https://onlinelibrary.wiley.com/journal/14680299)
- [Journal of Economic Perspectives](https://www.aeaweb.org/journals/jep)

For a full list of supporting journals, visit the [DCAS website](https://datacodestandard.org/journals/).

> ğŸ“ Journal-specific requirements may varyâ€”always consult their latest submission guidelines to ensure full compliance.


---

## ğŸ™ Acknowledgements

This project was inspired by:

- [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)

Maintained by the **CBS High-Performance Computing (HPC)** team.

---

## ğŸ“¬ Support

For questions, suggestions, or bug reports:

- Open an [Issue on GitHub](https://github.com/CBS-HPC/replication_package/issues)
- Or contact: [kgp.lib@cbs.dk](mailto:kgp.lib@cbs.dk)

---
