{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "code_data_network.py  ──  Build & visualise “scripts ↔ datasets” networks\n",
    "--------------------------------------------------------------------------\n",
    "\n",
    "• Reads ignore-patterns from  .nwignore   (git-style glob rules)\n",
    "• Reads dataset metadata   from  datasets.json\n",
    "• Recognises source files   *.py, *.R, *.m, *.do, *.sas   anywhere inside src/\n",
    "• Creates a DiGraph with\n",
    "      – script   nodes        (type='script')\n",
    "      – dataset  *hub* nodes  (type='ds')      coloured by data_type\n",
    "      – data-file nodes       (type='file')    same colour / marker as hub\n",
    "• Edges:\n",
    "      dataset-hub ──► each data-file in that dataset\n",
    "      script      ──► data-file   if basename(data-file) is referenced in script\n",
    "• Legend shows one entry per dataset (shape) *grouped* by colour (=data_type)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "import fnmatch\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# CONSTANTS\n",
    "# -------------------------------------------------------------------------\n",
    "SCRIPT_EXTS = {\".py\", \".r\", \".m\", \".do\", \".sas\"}       # case-insensitive\n",
    "DEFAULT_COLOURS = {                                    # data_type ▸ colour\n",
    "    \"00_raw\":      \"#64b5f6\",   # blue\n",
    "    \"01_interim\":  \"#ffb74d\",   # orange\n",
    "    \"02_processed\": \"#81c784\"   # green\n",
    "}\n",
    "SHAPES = [\"o\", \"s\", \"^\", \"v\", \"D\", \"p\", \"h\", \"8\"]      # Matplotlib markers\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Ignore-file helpers\n",
    "# -------------------------------------------------------------------------\n",
    "def load_ignore_patterns(ignore_path: str | Path) -> List[str]:\n",
    "    \"\"\"Return list of glob patterns read from an ignore file.\"\"\"\n",
    "    patterns: List[str] = []\n",
    "    if Path(ignore_path).is_file():\n",
    "        for line in Path(ignore_path).read_text(encoding=\"utf-8\").splitlines():\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith(\"#\"):\n",
    "                patterns.append(line)\n",
    "    return patterns\n",
    "\n",
    "\n",
    "def is_ignored(path: str | Path,\n",
    "               patterns: List[str],\n",
    "               base_dir: str | Path) -> bool:\n",
    "    \"\"\"True if *path* matches any pattern.\"\"\"\n",
    "    rel = Path(path).resolve().relative_to(Path(base_dir).resolve())\\\n",
    "                    .as_posix()\n",
    "    for pat in patterns:\n",
    "        # A. literal “component”  (e.g. \".git\")\n",
    "        if all(c not in pat for c in \"*?[]/\"):\n",
    "            if pat in rel.split(\"/\"):\n",
    "                return True\n",
    "        # B. fnmatch against the entire relative path\n",
    "        if fnmatch.fnmatch(rel, pat):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Script discovery  (handles nested module folders)\n",
    "# -------------------------------------------------------------------------\n",
    "def collect_scripts(src_dir: str | Path,\n",
    "                    ignore_patterns: List[str],\n",
    "                    base_dir: str | Path) -> List[str]:\n",
    "\n",
    "    scripts: List[str] = []\n",
    "\n",
    "    for root, dirs, files in os.walk(src_dir):\n",
    "        # prune ignored directories\n",
    "        dirs[:] = [d for d in dirs\n",
    "                   if not is_ignored(Path(root, d), ignore_patterns, base_dir)]\n",
    "        for fn in files:\n",
    "            full = Path(root, fn)\n",
    "            if is_ignored(full, ignore_patterns, base_dir):\n",
    "                continue\n",
    "            if full.suffix.lower() in SCRIPT_EXTS:\n",
    "                scripts.append(str(full))\n",
    "\n",
    "    # order by prefix  s00_*, s01_*, … or folder prefix\n",
    "    def _prefix(p: str) -> int:\n",
    "        bn = Path(p).name.lower()\n",
    "        folder_bn = Path(p).parent.name.lower()\n",
    "        for cand in (bn, folder_bn):\n",
    "            if re.match(r\"s\\d{2}[_\\-]\", cand):\n",
    "                return int(cand[1:3])\n",
    "        return 999\n",
    "\n",
    "    return sorted(scripts, key=_prefix)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Dataset loader\n",
    "# -------------------------------------------------------------------------\n",
    "def load_datasets(json_path: str | Path) -> List[dict]:\n",
    "    if not Path(json_path).is_file():\n",
    "        raise FileNotFoundError(f\"No datasets file at {json_path}\")\n",
    "    return json.loads(Path(json_path).read_text(encoding=\"utf-8\"))\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Build graph\n",
    "# -------------------------------------------------------------------------\n",
    "def build_script_data_graph(src_dir: str = \"src\",\n",
    "                            dataset_json: str = \"datasets.json\",\n",
    "                            ignore_file: str = \".nwignore\") -> nx.DiGraph:\n",
    "    \"\"\"Return a DiGraph where         script ──> data_file  and  ds_hub ──> data_file.\"\"\"\n",
    "\n",
    "    base_dir = Path().resolve()\n",
    "    ignore   = load_ignore_patterns(Path(ignore_file))\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # 1. scripts ----------------------------------------------------------\n",
    "    scripts = collect_scripts(src_dir, ignore, base_dir)\n",
    "    for s in scripts:\n",
    "        G.add_node(s, type=\"script\")\n",
    "\n",
    "    # 2. datasets + files -------------------------------------------------\n",
    "    entries = load_datasets(dataset_json)\n",
    "\n",
    "    # colour map for data_type  (use default colour if unknown type)\n",
    "    colour_for: Dict[str, str] = DEFAULT_COLOURS.copy()\n",
    "\n",
    "    # generate marker cycles *per* data_type\n",
    "    marker_cycle_by_type: Dict[str, itertools.cycle] = {}\n",
    "\n",
    "    # helper maps\n",
    "    ds_to_files: Dict[str, List[str]] = {}\n",
    "    file_to_ds: Dict[str, str] = {}  # data_file → ds_hub\n",
    "\n",
    "    for entry in entries:\n",
    "        d_type   = entry.get(\"data_type\", \"unknown\")\n",
    "        ds_name  = entry.get(\"data_name\",  \"unnamed\")\n",
    "        marker_cycle_by_type.setdefault(d_type, itertools.cycle(SHAPES))\n",
    "        marker = next(marker_cycle_by_type[d_type])\n",
    "\n",
    "        # Create / remember hub node (destination)\n",
    "        ds_path = Path(entry[\"destination\"]).resolve()\n",
    "        G.add_node(str(ds_path),\n",
    "                   label=ds_name,\n",
    "                   type=\"ds\",\n",
    "                   colour=colour_for.get(d_type, \"#cccccc\"),\n",
    "                   shape=marker,\n",
    "                   data_type=d_type)\n",
    "        ds_to_files[str(ds_path)] = []\n",
    "\n",
    "        # Create file nodes and connect hub → file\n",
    "        for file_path in entry.get(\"data_files\", []):\n",
    "            f_path = Path(file_path).resolve()\n",
    "            if is_ignored(f_path, ignore, base_dir):\n",
    "                continue\n",
    "            G.add_node(str(f_path),\n",
    "                       label=f_path.name,\n",
    "                       type=\"file\",\n",
    "                       colour=colour_for.get(d_type, \"#cccccc\"),\n",
    "                       shape=marker,\n",
    "                       data_type=d_type)\n",
    "            G.add_edge(str(ds_path), str(f_path))\n",
    "            ds_to_files[str(ds_path)].append(str(f_path))\n",
    "            file_to_ds[str(f_path)] = str(ds_path)\n",
    "\n",
    "    # 3. script → file edges ---------------------------------------------\n",
    "    for script in scripts:\n",
    "        try:\n",
    "            text = Path(script).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        except OSError:\n",
    "            text = \"\"\n",
    "        for file_node in file_to_ds:              # only file nodes\n",
    "            if Path(file_node).name in text:\n",
    "                G.add_edge(script, file_node)\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Drawing utilities\n",
    "# -------------------------------------------------------------------------\n",
    "def plot_script_data_graph(G: nx.DiGraph) -> None:\n",
    "    \"\"\"Visualise the graph with scripts (x=0), dataset hubs (x=1), files (x=2).\"\"\"\n",
    "\n",
    "    # --- ordering -------------------------------------------------------\n",
    "    scripts = sorted([n for n, d in G.nodes(data=True) if d[\"type\"] == \"script\"])\n",
    "\n",
    "    ds_hubs  = sorted([n for n, d in G.nodes(data=True) if d[\"type\"] == \"ds\"])\n",
    "    files    = sorted([n for n, d in G.nodes(data=True) if d[\"type\"] == \"file\"])\n",
    "\n",
    "    # keep files ordered under their datasets (appearance order)\n",
    "    ordered_files: List[str] = []\n",
    "    for ds in ds_hubs:\n",
    "        ordered_files.extend(nx.descendants(G, ds))   # children are files\n",
    "    # append any stray files not connected to hub (shouldn’t happen)\n",
    "    ordered_files.extend(f for f in files if f not in ordered_files)\n",
    "\n",
    "    # --- layout ---------------------------------------------------------\n",
    "    pos: Dict[str, Tuple[int, int]] = {}\n",
    "    for i, s in enumerate(scripts):\n",
    "        pos[s] = (0, -i)\n",
    "    for i, ds in enumerate(ds_hubs):\n",
    "        pos[ds] = (1, -i)\n",
    "    for i, f in enumerate(ordered_files):\n",
    "        pos[f] = (2, -i)\n",
    "\n",
    "    # --- draw nodes -----------------------------------------------------\n",
    "    plt.figure(figsize=(12, max(len(scripts), len(ordered_files))*0.35 + 1))\n",
    "\n",
    "    # scripts\n",
    "    nx.draw_networkx_nodes(G, pos,\n",
    "                           nodelist=scripts,\n",
    "                           node_color=\"#9fa8da\",\n",
    "                           node_shape=\"s\",\n",
    "                           label=\"Scripts\")\n",
    "\n",
    "    # datasets + file nodes grouped by (colour, shape)\n",
    "    done: set[Tuple[str, str]] = set()\n",
    "    for node in ds_hubs + ordered_files:\n",
    "        colour = G.nodes[node][\"colour\"]\n",
    "        shape  = G.nodes[node][\"shape\"]\n",
    "        key    = (colour, shape)\n",
    "        nodes_with_style = [n for n in ds_hubs + ordered_files\n",
    "                            if (G.nodes[n][\"colour\"], G.nodes[n][\"shape\"]) == key]\n",
    "        if key not in done:\n",
    "            nx.draw_networkx_nodes(G, pos,\n",
    "                                   nodelist=nodes_with_style,\n",
    "                                   node_color=colour,\n",
    "                                   node_shape=shape,\n",
    "                                   label=G.nodes[nodes_with_style[0]][\"label\"])\n",
    "            done.add(key)\n",
    "\n",
    "    # --- edges & labels -------------------------------------------------\n",
    "    nx.draw_networkx_edges(G, pos,\n",
    "                           arrowstyle=\"-|>\",\n",
    "                           arrowsize=12)\n",
    "\n",
    "    labels = {n: G.nodes[n].get(\"label\", Path(n).name) for n in G.nodes}\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=8)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.legend(title=\"Datasets (shape per dataset; colour per data_type)\",\n",
    "               scatterpoints=1, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# CLI helper\n",
    "# -------------------------------------------------------------------------\n",
    "def main():\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Build & plot Script ↔ Dataset network\")\n",
    "    parser.add_argument(\"--src\",  default=\"src\",  help=\"source code directory\")\n",
    "    parser.add_argument(\"--data\", default=\"datasets.json\",\n",
    "                        help=\"datasets.json path\")\n",
    "    parser.add_argument(\"--ignore\", default=\".nwignore\",\n",
    "                        help=\"ignore file with glob patterns\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    G = build_script_data_graph(src_dir=args.src,\n",
    "                                dataset_json=args.data,\n",
    "                                ignore_file=args.ignore)\n",
    "\n",
    "    if G.number_of_edges():\n",
    "        plot_script_data_graph(G)\n",
    "    else:\n",
    "        print(\"No links found between scripts and datasets.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93684453",
   "metadata": {},
   "outputs": [],
   "source": [
    "  main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
